Operator: Good afternoon, and welcome to the Third Quarter Fiscal 2024 Hewlett Packard Enterprise Earnings Conference Call. My name is Gary, and I'll be your conference moderator for today's call. At this time, all participants will be in listen-only mode. We will be facilitating a question-and-answer session towards the end of the conference. [Operator Instructions] As a reminder, this conference is being recorded for replay purposes. I would now like to turn the presentation over to your host for today's call, Paul Glaser, Head of Investor Relations. Please proceed.

Paul Glaser: Good afternoon. I'm Paul Glaser, Head of Investor Relations for Hewlett Packard Enterprise. I would like to welcome you to our fiscal 2024 third quarter earnings conference call, with Antonio Neri, HPE's President and Chief Executive Officer; and Marie Myers, HPE's Chief Financial Officer. Before handing the call to Antonio, let me remind you that this call is being webcast. A replay of the webcast will be available shortly after the call concludes. We have posted the press release and the slide presentation accompanying the release on our HPE Investor Relations web page. Elements of the financial information referenced on this call are forward-looking and are based on our best view of the world and our businesses as we see them today. HPE assumes no obligation and does not intend to update any such forward-looking statements. We also note that the financial information discussed on this call reflects estimates based on information available at this time and could differ materially from the amounts ultimately reported in HPE's quarterly report on Form 10-Q for the fiscal quarter ended July 31, 2024. For more detailed information, please see the disclaimers on the earnings materials relating to forward-looking statements that involve risks, uncertainties, and assumptions. Please refer to HPE's filings with the SEC for a discussion of these risks. For financial information we have expressed on a non-GAAP basis, we have provided reconciliations to the comparable GAAP information on our website. Please refer to the tables and slide presentation accompanying today's earnings release on our website for details. Throughout this conference call, all revenue growth rates, unless otherwise noted, are presented on a year-over-year basis and adjusted to exclude the impact of currency. Finally, Antonio and Marie will reference our earnings presentation in their prepared remarks. With that, let me turn it over to Antonio.

Antonio Neri: Thank you, Paul, and welcome to your new role leading investor relations at HPE. And thank you, all, for joining us today. HPE delivered a strong third quarter performance. We generated impressive revenue growth with notable acceleration of AI systems revenue conversion, as well as higher operating margin from the prior quarter. Net revenue was $7.7 billion, up 10% year-over-year and at the high end of our guidance. Non-GAAP diluted net earnings per share rose $0.01 from a year ago to $0.50 in Q3, $0.02 above the high end of our guidance. We generated a free cash flow of more than $660 million, and will pay a dividend of $0.30 per share. Based on our year-to-date performance, we are raising our full year GAAP and non-GAAP earnings per share guidance. Marie will provide further details in her remarks. Lastly, we are also pleased to have received the first payment of $2.1 billion in proceeds from the sale of part of our equity position in H3C. Overall, the demand environment this quarter has improved. We saw sequential and year-over-year orders growth, but with some geographic variation. Demand was strong in North America, Asia-Pacific, Japan and India, while Europe and the Middle East lagged. We are aggressively going after the opportunities presented by better market conditions and are well-positioned in a competitive and dynamic environment as we close our fiscal year. I am very proud of the progress we have made in delivering on our edge-to-cloud vision over the last several years, which is generating this performance momentum. We have accelerated innovation across all pillars of our strategy. Networking, hybrid cloud, and AI delivered through a unified cloud-native and AI-driven experience as a part of our HPE GreenLake cloud platform. Today, almost 37,000 unique customers use our HPE GreenLake cloud to manage their hybrid IT estate, which drives our annualized revenue run rate subscription growth. In Intelligent Edge, we have invested in building an industry-leading AI-driven networking portfolio. HPE Aruba Networking is a recognized market leader in the campus and branch segment. The AI market requires a modern, high-performing networking fabric as a core foundation to deliver a more efficient data center cloud infrastructure as the world transitions to accelerated computing. We are excited to significantly expand our networking business with the pending acquisition of Juniper Networks. The acquisition of this high-margin business will accelerate our edge-to-cloud vision with a full networking IP stack, from silicon to infrastructure, to the operating system, to security, to software and services in a cloud-native and AI-driven approach. We expect our compelling value proposition will begin to deliver returns to our shareholders in the year post close. In Hybrid Cloud, we redefine the cloud space by delivering an experience that is hybrid by design, with HPE GreenLake at the core of our strategy. We have transitioned our HPE server and HPE storage products to cloud-native and software-defined solutions while adding unique software and services to our HPE GreenLake cloud platform. Our innovation gives customer choice and flexibility across all workload types, while managing their public on-prem colos and edges in one unified hybrid cloud operations experience. Our AI business is built on decades of large-scale infrastructure expertise, including technologies like direct liquid cooling that they're powering our largest AI systems for large language model builders, service providers, and supercomputing users. We have rapidly expanded our AI portfolio, including the introduction of HPE Private Cloud AI, specifically engineered for enterprise customers, with the expectation of significant market expansion as we are still in the early stages of adoption. Pursuing this strategy has diversified the HPE portfolio to parts of the market with higher margins. Our differentiation not only makes us highly relevant to customers and partners, but also drives profitable growth for our shareholders. I have a few observations about Q3 performance in our key segments that I will share, and then I will let Marie fully review more detailed results. Our Server segment, again, outperformed expectations in Q3, thanks to an acceleration in converting AI system orders to revenue. We converted about $1.3 billion in AI systems revenue this quarter, a 39% increase from Q2. Revenue from our traditional server business also climbed with a double-digit increase in product orders, both sequentially and year-over-year, reflecting an improvement in the market for traditional compute. We continue to pursue profitable deals within our target server margin range, underscoring stability in our operating profit profile. In AI, our momentum is very clear. Customer demand for HPE AI systems rose sequentially, with opportunities increasing in both enterprise and sovereign AI clouds as customers explore more use cases. AI system orders climbed $1.6 billion in the quarter to a cumulative $6.2 billion since Q1 2023, an increase of approximately $3.5 billion over the last year. Customers are exploring new ways to use AI, adding to our already robust pipeline and creating even more runway for our broad AI offerings. Enterprise interest in generative AI is high, and while adoption is still in the initial stages, it is accelerating. Customers tell us that they see the possibilities and are building the business cases. We see use cases across multiple verticals, from healthcare to financial services to manufacturing. As the use cases mature, they need expertise to help guide the implementation across their enterprise business, not just IT. Direct liquid cooling continues to be a key differentiator and demand driver with large-scale AI customers. The expertise in IP required to build and run large direct liquid cooled systems creates a significant margin rich services opportunity for day zero, day one, and day two operations. HPE has one of the largest water cooling manufacturing and services footprint in the world. In the sovereign space, just recently, the U.S. Department of Energy National Renewable Energy Laboratory announced that its HPE-built Kestrel supercomputer came fully online over the summer. Kestrel will be five times more powerful than NREL's previous supercomputer, Eagle, and is 100% direct liquid cooled. This system will enable research advancing energy efficiency, sustainable transportation, renewable energy, and energy system integration, including by leveraging the latest innovation in AI large language model, modeling, and simulation. You saw at HPE Discover that HPE is deepening our strong partnership with NVIDIA. In June, we jointly announced NVIDIA AI Computing by HPE, a portfolio of codeveloped AI solutions and joint go-to-market integrations that enable enterprises to accelerate adoption of generative AI. One of those solutions, HPE Private Cloud AI, which just became generally available yesterday, is a turnkey solution that makes it easy for enterprises of all sizes to gain an energy-efficient, fast and flexible option for sustainably developing and deploying generative AI applications. To this adoption, HPE Private Cloud AI will be available in four modular configurations. These start with small-for-small model inferencing needs on NVIDIA L40 and scale up to extra large on NVIDIA Grace Hopper 200s for a configuration that allows for multiple use cases, running inferencing retrieval, augmentation generation, and large language model fine-tuning. We are offering customers two important choice points: self-managed or fully-managed service, with the ability to purchase as-a-service through an operating expenditure model or as a capital expense. With three clicks and less than 30 seconds to deploy, HPE Private Cloud AI dramatically simplifies DevOps, ITOps and FinOps for enterprise customers, allowing them to easily establish and meter their environments, monitor and observe their infrastructure and applications, and lifecycle manage all aspects of their private cloud AI system. And just last week, we further expanded our NVIDIA partnership by adding NVIDIA NIM Agent Blueprints to HPE Private Cloud AI for multiple generative AI use cases. This includes a digital human workflow for customer service, a generative virtual screening workflow for computer-aided drug discovery, and a PDF data extraction workflow for enterprise RAG that uses vast quantity of business data for more accurate responses. Integrating this catalog of pretrained, customizable AI workflows into our HPE Private Cloud AI stack enables customers to easily deploy key AI use cases to accelerate time to value. With a series of announcements about HPE Private Cloud AI, we are well-positioned to serve our enterprise customer needs. Since the announcement less than three months ago, we have seen very high customer interest, with requests for proof of concept demos exceeding our expectations. We are increasing sales resources and enabling our partner ecosystem to meet the high demands for demos. We believe HPE Private Cloud AI is going to be an important growth driver for our hybrid cloud business, and we are filing numerous patents to ensure our leadership is recognized and protected. This innovation and customer interest positions HPE Hybrid Cloud well, as AI is an accelerator for hybrid cloud solutions. We are on a positive trajectory with orders and we are beginning to realize returns from an ongoing investment in both our product portfolio and our specialized sales motions. There is more work to do, but we are pleased that our revenue and profitability both improved quarter-over-quarter. Customers require new data protocols in file and object to store and manage data to train AI applications. We expect that extending our HPE Alletra Storage software-defined offerings to these new data protocols will lead to a higher proportional software and related services in our portfolio. We are seeing double-digits orders growth in HPE Alletra Storage and in HPE GreenLake hybrid cloud SaaS offerings. In just the last three months, almost 3,000 new customers began using our HPE GreenLake cloud, and we added almost 10,000 more customers in the last year. We are pleased with the momentum we are seeing with customers who have turned into HPE GreenLake. We are proud to announce a new agreement with Deloitte to utilize the HPE GreenLake cloud to help transform and centralize Deloitte's IT infrastructure, which includes AI computing. We continue to introduce new hybrid cloud offerings by adding more profitable software and services, which is clearly reflected in our ARR mix now at 71%. For example, at the end of August, we closed our acquisition of Morpheus Data. We believe this acquisition solidifies HPE's leadership position as the first vendor with a full suite of software capabilities across the hybrid cloud stack. We look forward to integrating Morpheus Data multi-cloud automation and orchestration capabilities into our HPE GreenLake cloud platform to complement the AI-driven multi-cloud and multi-vendor observability from HPE's OpsRamp acquisition and our own organic innovation. In Intelligent Edge, we believe we are beginning a market recovery as customers finished digesting previous orders post-COVID. Revenue improved sequentially on gains in services and SASE. Momentum is building and we saw sequential orders increase in all regions with particular strength in North America. On the products front, orders growth was led by wireless LAN, SASE, and data center networking products. Conversely, campus-switching products orders have been slower to recover. Last month, we reinforced HPE Aruba Networking cyber defenses with the new AI-powered network detection and response and campus-based zero trust network access. The solution leverages telemetry from HPE Aruba Networking Central's data lake to train and deploy AI models to monitor and detect unusual activity in vulnerable IoT devices, helping to support mission-critical business processes. Our security solutions are attracted to customers like Nobu Hotels, which is leveraging a secure AI power network combining the HPE Aruba Networking Central platform and HPE Aruba Networking ClearPass to implement a zero trust strategy. This installation will help provide secure, seamless and hyper-personalized guest experiences, including an AI concierge across Nobu's global footprint on luxury hotels. We are excited for what comes next with our pending Juniper Networks acquisition and the comprehensive networking profile we will create. As I have said before, we expect that Juniper will be accretive to our margin profile and non-GAAP EPS in year one. The deal recently received regulatory approvals in the European Union, UK, India, and several other jurisdictions and we remain on track to close in late calendar year 2024 or early calendar year 2025. Plans are well underway to ensure successful integration post close. To conclude, I am very pleased with our third quarter performance. Our impressive revenue growth reflects the strength of our portfolio and the growing excitement customers have for our newest innovations across AI, network and hybrid cloud. HPE is playing a crucial role in helping customers adopt this transformative technology across their business. As we innovate, we also continue to stay disciplined in the way we manage our business and cost structure. In Q3, we delivered profitable growth for our shareholders in a competitive and dynamic environment. Next month, we look forward to hosting some of you at our incredible Wisconsin manufacturing facility, where we will build many of our industry-leading direct liquid cooled AI systems. The work we do there plays a key role in driving the transition to direct liquid cooled systems and the successful AI revenue conversion we saw this quarter. I hope you will take advantage of this opportunity to experience this. Now, I will hand it over to Marie to go through the segment results in greater detail. Marie?

Marie Myers: Thank you, Antonio, and good afternoon. We are pleased with our performance this quarter and we did what we said we would do. We delivered strong top-line revenues, grew revenues sequentially in each segment, prudently managed costs, improved profitability sequentially, and delivered non-GAAP diluted net earnings per share that exceeded the high end of our guidance range. As Antonio said, we are pleased to have received the $2.1 billion in proceeds from the partial sale of the H3C equity position. Today's results highlight our ability to deliver amidst a dynamic macro environment. While some customers remain cautious and prioritize mission-critical projects, we are encouraged by the recovery in enterprise demand we are seeing in North America, followed by modest improvement across the other geographies. We remain excited about HPE's position across AI, hybrid cloud, and networking. HPE is well-positioned for the AI opportunity. This quarter, our AI systems backlog increased and we grew AI systems revenues approximately 40% sequentially. We continue to win deals with both model builders and sovereigns and are well-positioned to address enterprise AI demand. In traditional servers, we are seeing signs of a recovery as both demand and revenue increase sequentially. In hybrid cloud, we see an improvement in storage, led by the strong demand for our HPE Alletra MP offering, and we continue to drive ARR growth. We are encouraged by the early and strong customer response to our Private Cloud AI offering that we announced at Discover, which we expect to drive AI adoption in the enterprise. Lastly, results were solid in networking. Improving sequential demand in WLAN, data center networking and switching, along with continued growth in security and services, keeps us optimistic heading into the fourth quarter. We continue to make progress towards our strategic goals. Our recently announced acquisition of Morpheus Data that expands our hybrid cloud capabilities and our confidence in closing the Juniper acquisition by the end of calendar year 2024 or early calendar year 2025 are excellent examples. Overall, I am pleased with our performance in Q3 and look forward to carrying our momentum through the end of our fiscal year. Now, let me go through the details of the quarter. Revenue grew 10% year-over-year and 7% quarter-over-quarter in constant currency to $7.7 billion, near the high end of our guidance range for the quarter. Our as-a-service momentum continued this quarter. We grew ARR 39% in constant currency year-over-year to more than $1.7 billion, led by AI through HPE GreenLake and networking and storage subscriptions. With enterprise AI customers, we are noticing a strong appetite for a consumption model, both to alleviate investment pressures as well as to retain flexibility to grow workloads, though this is still early days. We continue to lift HPE GreenLake's value proposition with an increasing mix of higher-margin software and services revenue. This quarter, we expanded the software and services mix of ARR approximately 300 basis points year-over-year to 71%, due to the stronger sales of AI services tied to hardware sales and Aruba Central platform subscriptions. Our non-GAAP gross margin was 31.8%, which was down 410 basis points year-over-year, driven by a lower mix of Intelligent Edge revenue and a higher mix of AI server revenue. The 130-basis-point sequential decline was driven by the higher AI server revenue mix. We have balanced gross margin pressures by executing on strong cost controls and by maintaining pricing discipline in a competitive AI server market. Our non-GAAP operating expenses decreased approximately 7% year-over-year and 1% quarter-over-quarter despite a seasonal increase in marketing expenses associated with our annual Discover event. Since joining as CFO, I have taken a rigorous, programmatic approach to streamlining our cost structure to drive operating expense improvements. And we expect to see the benefits of these actions in the second half of the year. This is already evident in our results as we drove a 50-basis-point sequential improvement in our non-GAAP operating margin, offsetting pressures we saw at the gross margin line. Our non-GAAP operating margin was stable at 10%. Profitability improvements and better-than-expected OI&E drove GAAP-diluted net EPS of $0.38 per share and our non-GAAP diluted net EPS of $0.50 per share, both above the high end of our guidance ranges. Our non-GAAP diluted net EPS excludes $149 million in net costs, primarily from stock-based compensation expense, amortization of intangibles and acquisition, and other related charges. Now, let's turn to the segment results, starting with Servers. Strength in both AI systems and traditional servers drove healthy revenue growth and stable operating margins. Server revenues were $4.3 billion in the quarter, up 35% year-over-year and 11% sequentially. In traditional servers, we saw steady growth and are seeing signs of a recovery. We saw strength in North America where our installed base is spending more, though EMEA and APJ customers continue to evaluate spend. Our Gen11 product continues to ramp ahead of expectations and now represents a growing proportion of total server revenue. And we have been able to manage an inflationary component environment through dynamic pricing and by leveraging strong supplier relationships. In AI systems, demand remains strong, though large deals continue to be lumpy. AI systems product and services orders rose $1.6 billion sequentially, driving our cumulative orders since Q1 '23 to $6.2 billion. We are pleased with our current AI systems backlog, which has increased quarter-over-quarter to $3.4 billion. Demand remains healthy from the model builders. We are winning deals in this space and following a framework to manage risks and profits. While still early days, we continue to see positive signs from enterprise customers. In fact, more than 80% of enterprises are experimenting with GenAI initiatives, which supports our view that the number of customers will continue to trend favorably. This quarter, our enterprise AI pipeline more than doubled sequentially. And sovereign AI is an adjacency for HPE, right beside our market leadership in supercomputing. We continue to see increasing demand from this set of customers who are embracing AI. Within model builders and sovereign AI, customers is a growing desire for liquid cooling. However, adoption relies on data center readiness. We view HPE's multi-decade design and manufacturing expertise, intellectual property, patent portfolio, and global reach and dedicated services as clear differentiators as the market moves in this direction. Q3 was again a strong quarter for AI system revenue conversion. AI system revenues were $1.3 billion in the quarter, up approximately 40% from the prior quarter. We are pleased with the stability of our operating margins within our Server business. Our Q3 Server operating margin was 10.8%. This was up 70 basis points year-over-year, but down 20 basis points sequentially. AI systems make up a higher share of our total Server revenue compared to one year ago, 10% in Q3 FY '23 versus 30% this quarter. This underscores our disciplined focus on profitability in a competitive AI server market. Our operating margin performance was in line with expectations. For the full year, we continue to expect our Server margins to be at the low end of our target range of 11% to 13%. We will remain disciplined in cost and price as we pursue profitable growth. Now, moving to Hybrid Cloud. Both revenue and profitability improved quarter-over-quarter. Segment revenues of $1.3 billion were down 7% year-over-year, but up 4% sequentially. As we have previously discussed, we are managing both a sales model transition and product transition within the storage business. Our product model transition is to a more cloud-native, software-defined platform with HPE Alletra, which offers a unified storage architecture, comprehensive AIOps, and cross-stack analytics and aligns to customer preferences for a hybrid cloud model. Translating this storage growth to revenues will take time because of the higher mix of ratable software and services, which is deferred into future periods. We continue to see strength for our Alletra MP offering with sequential improvement led by our continued business transformation efforts, particularly in go-to-market. We are seeing signs of improving demand for block storage and early traction in file, and we are closely monitoring the impacts of commodity costs on demand. In our Private Cloud business, we are having constructive conversations with our customers to evaluate their virtualization strategy. At Discover, we announced efforts to develop our virtualization capabilities, which will be available within our Private Cloud Business Edition solution. Lastly, customers are reacting positively to our recently announced Private Cloud AI offering in partnership with NVIDIA, which unifies AI skills, data, architecture and solutions into one fully managed platform and accelerates time to value for enterprises looking to begin their AI journeys. We are seeing traction in both customer demos and pipeline, and as of yesterday, our Private Cloud AI offering is globally available to order. Our Hybrid Cloud operating margin was 5.1%, down 30 basis points year-over-year, but up 430 basis points sequentially, predominantly due to better OpEx controls. Moving to Intelligent Edge. Revenues were $1.1 billion, down 23% year-over-year on tough compares, but up 3% sequentially. Demand was steady quarter-over-quarter, backlog remains at normal levels, channel inventory remains healthy, and we believe that we have moved past the trough. On the order side, we are seeing a recovery that is in line with our industry peers. For the second consecutive quarter, we saw order improvements in each of our geographies, led by strength in North America, followed by modest growth at EMEA and APJ. By product, we saw sequential order improvements in data center networking and in in-campus. We grew both services and SASE orders mid- to high-single-digits year-over-year as customers remain excited about our Aruba Central platform that is part of our HPE GreenLake offering. On the revenue side, we drove year-over-year strength in data center networking, SASE, and services, though saw declines in our campus and switching due to difficult annual compares. Our sequential revenue grew approximately 3%, consistent with our expectation that Q2 would be the trough. The segment operating margin of 22.4% was down 520 basis points year-over-year, driven by tough year-over-year revenue compares, offset slightly, but a better year-over-year gross margin rate. Better OpEx was the primary reason for our 60-basis-point sequential improvement in operating margin. Our OpEx plan has put us on a path to achieve operating margins in the mid-20% range by Q4. Now, turning to Financial Services. Our HPE Financial Services revenue were $879 million, up 1% year-over-year, and financing volumes were $1.5 billion. Year-to-date, $800 million of $4.5 billion in financing volume went to AI wins with both cloud and enterprise customers, which illustrates that AI is driving demand across our portfolio. Operating margin of 9% was up 80 basis points year-over-year and down 30 basis points sequentially. Our portfolio remains healthy, and we continue to improve the investment-grade mix. Our Q3 loss ratio remained steady at below 0.5% and our return on equity is a solid 17.4%. Turning now to cash flow and capital allocation. We generated $1.2 billion in cash flow from operations and $669 million in free cash flow. We are on track for $1.9 billion in free cash flow. We remain confident in our ongoing ability to generate strong free cash flow even as we pursue strategic buys given the rising component cost environment. Our Q3 cash conversion cycle was a positive four days, which is a reduction of 19 days from Q3 '23. Our days of inventory and days of payables were both higher on AI systems orders that outpaced revenue conversion and on our strategic purchases for our server business. We continue to believe working capital to be neutral to free cash flow as we expect declines in inventory led by strong AI system revenue conversion to balance declines in accounts payable as we exit the year. We are pleased to have received the $2.1 billion in proceeds from the partial sale of the H3C equity position. We remain committed to our balanced capital allocation framework and are focused on managing our balance sheet and maintaining our dividend. We returned $221 million in capital to shareholders in Q3 and $607 million year-to-date. Now, let's turn to guidance. As Antonio mentioned, we are making steady progress on securing the necessary regulatory approvals required for our pending Juniper acquisition and look forward to closing by the end of calendar year '24 or early calendar year '25. For the fourth quarter, we expect revenues in the range of $8.1 billion to $8.4 billion, GAAP diluted net EPS to be between $0.76 and $0.81, and our non-GAAP diluted net EPS to be between $0.52 and $0.57. For revenue, we expect to see sequential growth similar to the last couple of quarters with revenue to remain indexed towards server. We continue to manage the business at the operating income level and, therefore, expect a sequential decline in operating expenses in order to deliver our EPS targets. On a segment basis, we expect the following. For Server, we expect to convert AI systems to revenue at a strong pace. As mentioned, the market remains competitive and large deals remain lumpy. We continue to be time-to-market for GPUs and are looking forward to shipping H200 chips for the AIST supercomputer in Q4. We also expect a continued demand in traditional servers, driven by Gen11 adoption and higher units. We are maintaining our expectation of achieving the low end of our 11% to 13% operating margin range for the full year. For Hybrid Cloud, we expect a slight revenue increase to close the year, though expect pressures from rising commodity costs, particularly in SSDs. ARR growth should continue as our storage business accelerates and shifts to subscription under HPE GreenLake. And we expect operating margins to continue to trend favorably to the mid-single-digit range. For the Intelligent Edge business, we anticipate a slight sequential revenue increase for the fourth quarter on the recovery in campus and WLAN, as well as strength in data center networking. Benefits from our cost reduction efforts materialized in our third quarter results, and we expect a similar trend in the fourth quarter, supporting our outlook for a full year operating margin in the mid-20% range. For the full year, we are tracking towards the high end of our revenue guidance of 1% to 3% growth in constant currency. We expect to balance gross margin pressures from a higher mix of AI systems with continued operating discipline and expect to come in at the low end of our operating profit growth guidance of 0% to 2%. We now expect OI&E to be a $50 million to $100 million headwind versus our prior expectation of $150 million headwind. We have tightened our non-GAAP diluted net EPS expectations for the full year to $1.92 to $1.97. For GAAP EPS, we are now seeing increased costs related to the Juniper transaction, with our expectations now at $1.68 to $1.73. Lastly, we remain committed, in the long term, to our balanced capital allocation framework, our dividend, and to our investment-grade rating. In the near term, we expect to continue share repurchases at a pace in line with Q3, as we prudently manage our balance sheet ahead of the Juniper transaction closing. To summarize, our Q3 results were strong and demonstrated good sequential revenue growth. With that, I'll turn it over for Q&A.

Operator: We will now begin the question-and-answer session. [Operator Instructions] The first question is from Meta Marshall with Morgan Stanley. Please go ahead.

Meta Marshall: Great. Thanks, and congrats on the results. Maybe just on the Server margins, given the AI revenue contribution, they were a little bit higher than expected. Could you just break down? Is this from kind of better ProLiant margins, better kind of proprietary Cray margins, just better pricing discipline? Just a little bit more insight into the margin strength we saw there? Thank you.

Marie Myers: Yeah, sure. Good afternoon, Meta, and thanks for your question on Server margins. First of all, as I said in my prepared remarks, we did, in fact, ship about $1.3 billion of AI servers in the quarter. So that constituted around about 30% of Server revenue. And despite that, our margins were at 10.8%. And to your point, what was it driven by? So, first of all, we're well on track on the shift to Gen11, and in itself, Gen11 has richer configurations and, therefore, comes with a higher margin profile. Also, I think we've been pretty successful at passing through those commodity costs, and despite the fact that we're in a pretty competitive both CPU and GPU environment. And then lastly, I'd say you would have seen that our OpEx was down sequentially and you're seeing the impact, frankly, of that OpEx discipline show up in the margins as well, Meta.

Paul Glaser: Okay. Thank you, Meta. Next question, please.

Operator: The next question is from Samik Chatterjee with JPMorgan. Please go ahead.

Samik Chatterjee: Hi, thanks for taking my question, and I apologize in advance if there's some background noise because I'm at the airport. I guess, we're getting the most questions today on the gross margin. And Marie, I know you outlined the factors there in terms of the AI server mix. But hoping you can flesh that out a bit more in terms of was there anything outside of the AI server mix that impacted gross margins at the company level in the quarter itself? And as we think about sort of your operating discipline going into the next quarter, should we be expecting sort of further moderation in the gross margins and more operating discipline to help maintain that operating margin outlook? And if I can just add on there, the AI order execution that you're seeing, you mentioned lumpy deals with customers. Is that impacting your thinking on gross margins for the aggregate company as we look forward as well in terms of where -- which verticals those orders are coming from? Thank you.

Marie Myers: Hey, Samik, good afternoon. So, I think I've got most of your questions. I'll hit it up in terms of gross margins and what we've seen. So first of all, I would say just if you step back and think about gross margins at a high level, from a year-on-year perspective, just to remind everybody that obviously the contribution from our networking revenue is lowest. Obviously, that's impacted gross margins from a year-on-year basis. Now, when you look sequentially, as I mentioned in prepared remarks, the AI mix of servers, we converted at a much faster pace. And obviously, that's really driven margin -- gross margin in the quarter. Now, I would add to your point, we've been offsetting it with prudency on OpEx. You've seen that we're going to continue to do that. I think I mentioned that in my guide comments. And then, also, we continue to have a mindset about being very disciplined on cost and price as we pursue profitable growth. I think we talked about the fact we're selective on deals. And you see that frankly, if you look at the quality of our receivables, you'll see it in our receivables. Now, a couple of things to sort of bear in mind as we go forward. As we see enterprise AI gain momentum, that's going to have a more favorable impact on gross margins. So, we do expect that we'll see improving profitability as the market moves in that direction. And then finally, Samik, just to sort of bear in mind that we're getting closer to the close of Juniper. We expect to see that the end of calendar '24, beginning of '25. In itself, that transaction is going to have a significant impact on both gross and operating margins. And we expect that more than 50% of the company's operating profit will come from networking. So that's how I'd sort of leave it with you in terms of thinking about margins. And as we said, we'll continue to focus on managing OpEx and being very prudent on deals.

Paul Glaser: Thank you, Samik. Gary, next question, please.

Operator: The next question is from Amit Daryanani with Evercore. Please go ahead. Amit, your line is open on our end, perhaps it's muted on yours.

Amit Daryanani: Sorry. Good afternoon. Thanks for taking my question. Marie, I was hoping you can talk a bit more about the free cash flow numbers. It was down a fair bit year-over-year. Maybe you can just talk about what is driving the downtick in free cash flow. Is there a way to think about the headwind you're seeing from the AI ramps versus the strategic pre-buys? Just talk about what those buckets are? And then, related to free cash flow, I think last quarter, it was at least $1.9 billion for the full year. I think this time it's $1.9 billion. So, seems like a bit of a downtick. Maybe I'm overthinking it, but could you just talk about how do you think about that October quarter free cash flow number as well? Thank you.

Marie Myers: Yeah, sure. No worries, Amit. And so, yeah, I think you probably are -- just in terms of where we're at in cash flow, let me hit Q3 and then I'll go into Q4. So, from a Q3 perspective, it's really driven by a couple of things. Firstly, the timing of working capital, and also just some of the normal seasonality that we see. And then, as we get into Q4, we do expect to see some of the benefits of working capital. So, we'll see a reversal in CCC, and that will benefit free cash flow. And then, obviously, we're going to see that stronger conversion of AI revenue. I think I mentioned in my prepared remarks that we're going to see a sequential improvement in the shipment of AI revenue. So, you can see that will also have an impact on our free cash flow. So, for the full year, Amit, I'd just say we are still on track for $1.9 billion. It's just as you could imagine, we're in Q3 now, we're getting into Q4, we sort of tightened up the expectations given where we're at in the year. So, still on track for $1.9 billion, Amit.

Paul Glaser: Very good. Thank you, Amit. Next question, please.

Operator: The next question is from Toni Sacconaghi with Bernstein. Please go ahead.

Toni Sacconaghi: Yes, thank you. You did mention repeatedly the lumpiness of AI server deals, and I'm wondering if there was any unusually large deals in Q3, or whether you're anticipating your AI bookings to be significantly different in Q4. And then just on the free cash flow, Marie, net income is going to be about $2.5 billion to $2.6 billion. Free cash flow is going to be about $1.9 billion. That's about 75% realization. I think since HPE split-off, free cash flow realization has actually been even lower than that. How do we think about that going forward? I presume free cash flow realization will be less than [1%] (ph) for next year and maybe even the following year because of Juniper integration charges? Or where is the pathway to where we can see free cash flow to net income being positive?

Antonio Neri: Yeah. Thank you, Toni. This is Antonio. I'm going to take the first part. The quick answer is no. There have not been very, very large deals or lumpy deals. It's been more spread and more uniform across the service provider space. And on the enterprise side, because obviously, we talk about this, the percentage of bookings relative to the $1.6 billion was -- as a mix, was in the mid-teens. So, very consistent with the prior year's quarter. However, obviously, the dollars are much larger, right, because now this quarter, we book $1.6 billion. So, I actually argue this is a good thing. And we don't expect significant super-large deals, I'd call it, in Q4 based on what we have visibility in the pipeline, but more a continuation of what we saw in Q3. And Marie, you want to talk about the free cash flow?

Marie Myers: Yeah. No, just, Toni, I mean, I think in terms of your comments on free cash flow, from an FY '24 perspective, I mean, in terms of bridging net earnings to free cash flow, it's the normal puts and takes for the year, so working capital, CapEx, et cetera. and sort of employee benefits. So, there is no specific charges in there in terms of our working capital -- sort of our net earnings for the year to free cash flow. In terms of '25, what we said, Toni, I think in the transaction stays the same. And look, honestly, we'll be guiding '25 when we do our next earnings call. So, I'll provide more color around free cash flow for '25 as we get into the next call.

Paul Glaser: All right. Thank you, Toni. Next question, please.

Operator: The next question is from Mike Ng with Goldman Sachs. Please go ahead.

Mike Ng: Hey, good afternoon. Thank you for the question. I just had a question about the mix of products and services for the AI systems orders and revenues that you guys disclosed on Slide 12. I guess, I was struck by two things. First, the growing share of services as a percentage of AI system orders, should we expect that to continue over time? And what are some of the key services you're selling with AI systems? And then, second, the very little services revenue that's being recognized to-date, as you recognize that services revenue in AI systems, should that improve the margins for server margins and AI system margins? And how much can that improve margins by? Thank you.

Antonio Neri: Yeah, thanks, Mike. Yeah, listen, we are very pleased with the services attached momentum on the AI systems portion of our business, which I believe will continue to grow as we grow the enterprise segment of the market, because that segment of the market comes with more rich services day zero, day one and day two services like we call it. And yesterday was the first day it became available out of HPE Private Cloud AI, and that has quite a bit of services component with it. And so -- but right now, as we started disclosing last quarter, the services component of that which you saw in one of the slides, as Marie was providing her remarks, much of that is pretty much all deferred. So, unless we are doing an installation and that gets recognized immediately, most of that is the maintenance that gets recognized over the length of the contract. And therefore, over time, we expect that will be contributing positive to our gross margins in the segment that we recognize that revenue, which obviously is the Server segment of the market. So, yes, but I'm positive on both gross margin accretion as we recognize the revenue and more services as we start selling the HPE Private Cloud in the enterprise space.

Paul Glaser: Thank you, Mike. Next question, please.

Operator: The next question is from Simon Leopold with Raymond James. Please go ahead.

Simon Leopold: Thank you very much. I wanted to see, Antonio, if you could talk a little bit about the trends with traditional servers, given we hear these arguments that AI-accelerated platforms would cannibalize traditional servers, but you're seeing good growth and good order patterns. How should we think about the risk that maybe that cannibalization eventually happens, or how are you really thinking about traditional versus AI? Thank you.

Antonio Neri: Yeah. Thank you, Simon. We have seen no signs of cannibalization into the traditional server market. And remember, I always try to bring a segment point of view, right? So, the segment point of view in the AI space, you have three segments. You have the service providers, model builders, which obviously include the hyperscalers, and there we have not sold traditional servers in a long time once we made the decision in 2017 to not participate in that market. And then, you have the sovereign space, which is now going up in term of interest, but the sales cycles are longer because of the government engagements and the procurement, but there, generally speaking, there is no traditional service per se. It's a combination of architectures and GPUs and CPUs in a unique form factor. And then last but not least, we have the enterprise. And the enterprise, while it's growing, has been very much focused on the AI applications. And for customers to move a traditional workload, call it, legacy workloads and the like, to a accelerated compute, the question is why you will do that when, A, you need to use the accelerated compute to either fine-tune the model or to do inferencing; and second, from a PCO perspective, there is no clear view that, that will be cost less. And so that's why when I think about workloads and customer segments, we don't see signs of cannibalization from the AI deployments into the traditional workloads.

Paul Glaser: Thank you, Simon. Gary, next question, please.

Operator: The next question is from Wamsi Mohan with Bank of America Merrill Lynch. Please go ahead.

Wamsi Mohan: Yeah, thank you so much. Antonio, I was wondering if you could just share some color on why the -- on what the AI backlog composition is across maybe your portfolio where you're seeing more strength versus not. And within the enterprise demand commentary that you're calling out, can you share some color on what kind of projects are being evaluated? I know you called out some verticals like healthcare and financial services. Curious if you could provide some color on that as well. Thank you so much.

Antonio Neri: Yeah. So, first of all, the pipeline we have in front of us is multiples of the current backlog, which is a positive news, because that tells you the momentum will continue in the next few quarters. Second is that the backlog composition, as I said, in the mid-teens is the enterprise space and the rest is the traditional service provider space. On the service provider space is basically compute capacity to train models or to do hosting for that matter, in large colos. And then, on the enterprise space is really focused on the use cases where they see clear line of sight for the return on that investment, and there are several use cases by segment that customers by verticals that they are driving. Obviously, many of them are very obvious. And now we are seeing a little bit more sophistication in some of those use cases and the maturity of. And that's why our Private Cloud AI offering is targeting those type of customers, because ultimately comes with entire stack from the, what I call, the workloads at the top, specifically designed for the verticals, down into the training models, all the way down to the infrastructure. They are sized for that type of deployment. And then, on the sovereign AI, obviously, we see now a significant interest. We are working across multiple geos on several opportunities. A lot of them are basically to open AI clouds for sovereign reasons or privates and compliance reasons on data. And a lot of them actually want to look a little bit like supercomputers in many ways because many of those systems are designed to do both AI large language models, and that's very obvious with some of the deployments we have done in the European Union and the one we're going to do now for the U.K. And other ones are basically for traditional supercomputing. So, the infrastructure in the end is the same. All of these systems are very much liquid cooled systems. And so, that's an opportunity for us. But on the enterprise side, I think you can see now expansion from traditional bots and customer service into other areas in finance, manufacturing, marketing, where they can see the clear return on that investment. And we're helping them even upfront through a partner ecosystem to define those use cases, because ultimately, it goes beyond just deploying IT, but they're really to realize the business value.

Paul Glaser: Thank you, Wamsi. Last question, please.

Operator: And the final question is from Ananda Baruah with Loop Capital. Please go ahead.

Ananda Baruah: Hey, guys, yeah, good afternoon. Really appreciate you taking the question. Maybe, Antonio, actually just dovetailing from there, like I'd love any more insight you can give a context around, like what's the HPE sort of sweet spot right now for business you win in GenAI, like what types of deployments or workloads? And then, how do you see that -- do you see that changing, or how do you see that evolving over the next few years as well? And that's it for me. Thanks, guys.

Antonio Neri: Well, I think right now, one of the key sweet spots is we now have to build and deploy and run these large systems. That requires a unique expertise. That's why you see the services portion being attached to those assistants. And ultimately, you need expertise both in the manufacturing space. And again, we're going to host our AI Day in one of, what I believe is, the largest footprints in the world where you can see how this gets done. And then, on the services side, you should not underestimate the services expertise needed to run. But for enterprise, where is the next big thing is -- in my view, is all about the simplicity. And several of the patterns we are actually filing and getting done are actually in areas like ease of use, automation, obviously, security. These are all spaces where we are actually building all those capabilities in our offer. And remember, all of this gets built inside HPE GreenLake as we deploy these optimized infrastructure and configurations. And that's why for me, GreenLake is an important component of our AI strategy, because ultimately, we manage a lot of the deployment on-prem through enterprise customers, specifically, through HPE GreenLake. And that's an accelerator and a way to upsell, cross-sell, build, ultimately, customers' confidence and control of the data, which is the fundamental value when it comes down to AI. And then, next year, once we close the Juniper transaction, we're going to add another key component, which is the networking piece. And it's very important that we recognize that AI, A, is a hybrid workload. The core foundation of that across hybrid is the network. And HPE will have unique IP and capabilities in that space in addition to the traditional server storage, which is now certified for AI, and then the GreenLake software and services attached to it. And that's how I want to think about it. Independent businesses are all accretive to AI, but then when we get to a solution, HPE will have the full-stack solution to offer to our enterprise customers.

Paul Glaser: Thank you very much. Antonio, any comments?

Antonio Neri: Yeah, no, thank you very much for the time. Again, I will say we delivered a strong quarter. We drove very strong revenue growth. We said what -- we did what we said. And honestly, I'm very confident about the next quarter and what comes next after the Juniper acquisition. I'm super-pleased that we also closed the first tranche of our H3C put option. Obviously, that took a lot of work in an environment that's complex. And as you think about our ability to deliver profitable growth is there. I understand the questions around margins, but when I think about margins, on the server side, we are consistently driving a stable around 11% or so operating margins. We think about that way more than gross margin because ultimately it's all about cash. And then, ultimately, on the networking and hybrid cloud is about both gross margin, because of our content is more software and services, while we'll deliver on the bottom-line. So, I think our strategy all coming together, but it's very competitive dynamic there and we have to execute every day with discipline, which is what we did again this quarter. And again, we raised guidance for the full year on the EPS side of the house. So, thank you very much for your time. And I look forward to hosting some of you at our facility in Wisconsin on October 10.

Paul Glaser: Very good. Thank you, everyone, for joining today.

Operator: Ladies and gentlemen, this concludes our call for today. Thank you.