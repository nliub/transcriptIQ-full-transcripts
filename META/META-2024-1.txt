Operator: Good afternoon. My name is Krista, and I will be your conference operator today. At this time, I would like to welcome everyone to the Meta First Quarter Earnings Conference Call. [Operator Instructions] This call will be recorded. Thank you very much.  Ken Dorell, Meta's Director of Investor Relations, you may begin. 

Kenneth Dorell: Thank you. Good afternoon, and welcome to Meta Platform's First Quarter 2021 Earnings Conference Call. Joining me today to discuss our results are Mark Zuckerberg, CEO; and Susan Li, CFO.  Before we get started, I would like to take this opportunity to remind you that our remarks today will include forward-looking statements. Actual results may differ materially from those contemplated by these forward-looking statements. Factors that could cause these results to differ materially are set forth in today's earnings press release and in our annual report on Form 10-K filed with the SEC.  Any forward-looking statements that we make on this call are based on assumptions as of today, and we undertake no obligation to update these statements as a result of new information or future events.  During this call, we will present both GAAP and certain non-GAAP financial measures. A reconciliation of GAAP to non-GAAP measures is included in today's earnings press release. The earnings press release and an accompanying investor presentation are available on our website at investor.fb.com.  And now I'd like to turn the call over to Mark. 

Mark Zuckerberg: All right. Thanks, Ken, and everyone, thanks for joining. It's been a good start to the year, both in terms of product momentum and business performance. We estimate that more than 3.2 billion people use at least one of our apps each day, and we're seeing healthy growth in the U.S. And I want to call out WhatsApp specifically, where the number of daily actives and message sends in the U.S. keeps gaining momentum, and I think we're on a good path there. We've also made good progress on our AI and metaverse efforts, and that's where I'm going to focus most of my comments today.  So let's start with AI. We're building a number of different AI services, from Meta AI, our AI assistant that you can ask any question across our apps and glasses, to creator AIs that help creators engage their communities and that fans can interact with, to business AIs that we think every business eventually on our platform will use to help customers buy things and get customer support to internal coding and development AIs to hardware like glasses for people to interact with AIs and a lot more.  Last week, we had the major release of our new version of Meta AI that is now powered by our latest model, Llama 3. And our goal with Meta AI is to build the world's leading AI service, both in quality and usage. The initial rollout of Meta AI is going well. Tens of millions of people have already tried it. The feedback is very positive. And when I first checked in with our teams, the majority of feedback we were getting was people asking us to release Meta AI for them wherever they are. So we've started launching Meta AI in some English speaking countries, and we'll roll out in more languages and countries over the coming months. You all know our product development playbook by this point. We release an early version of a product to a limited audience to gather feedback and start improving it, and then once we think it's ready, then we make it available to more people. That early release was last fall and with this release, we are now moving to that next growth phase of our playbook. We believe that Meta AI with Llama 3 is now the most intelligent AI assistant that you can freely use. And now that we have the superior quality product, we are making it easier for lots of people to use it within WhatsApp, Messenger, Instagram and Facebook.  Now in addition to answering more complex queries, a few other notable and unique features from this release. Meta AI now creates animations from still images and now generates high-quality images so fast that it can create and update them as you are typing, which is pretty awesome. I've seen a lot of people commenting about that experience online and how they've never seen or experienced anything like it before.  In terms of the core AI model and intelligence that's powering Meta AI, I'm very pleased with how Llama 3 has come together so far. The 8 billion and 70 billion parameter models that we released are best-in-class for their scale. The 400-plus billion parameter model that we're still training seems on track to be industry leading on several benchmarks. And I expect that our models are just going to improve further from open source contributions.  Overall, I view the results our teams have achieved here as another key milestone in showing that we have the talent, data and ability to scale infrastructure to build the world's leading AI models and services. And this leads me to believe that we should invest significantly more over the coming years to build even more advanced models and the largest scale AI services in the world. As we're scaling CapEx and energy expenses for AI, we'll continue focusing on operating the rest of our company efficiently. But realistically, even with shifting many of our existing resources to focus on AI, we'll still grow our investment envelope meaningfully before we make much revenue from some of these new products. I think it's worth calling that out that we've historically seen a lot of volatility in our stock during this phase of our product playbook, where we're investing in scaling a new product but aren't yet monetizing it. We saw this with Reels, Stories as newsfeed transition to mobile and more. And I also expect to see a multiyear investment cycle before we fully scale Meta AI, business AIs and more into the profitable services I expect as well. Historically, investing to build these new scaled experiences in our apps has been a very good long-term investment for us and for investors who have stuck with us. And the initial signs are quite positive here, too. But building the leading AI will also be a larger undertaking than the other experiences we've added to our apps, and this is likely going to take several years.  On the upside, once our new AI services reach scale, we have a strong track record of monetizing them effectively. There are several ways to build a massive business here, including scaling business messaging, introducing ads or paid content into AI interactions and enabling people to pay to use bigger AI models and access more compute. And on top of those, AI is already helping us improve app engagement, which naturally leads to seeing more ads and improving ads directly to deliver more value. So if the technology and products evolve in the way that we hope, each of those will unlock massive amounts of value for people and business for us over time.  We're seeing good progress on some of these efforts already. Right now, about 30% of the posts on Facebook feed are delivered by our AI recommendation system. That's up 2x over the last couple of years. And for the first time ever, more than 50% of the content that people see on Instagram is now AI recommended. AI has also been a huge part of how we create value for advertisers by showing people more relevant ads. And if you look at our 2 end-to-end AI-powered tools, Advantage+ shopping and Advantage+ app campaigns, revenue flowing through those has more than doubled since last year.  We're also going to continue to be very focused on efficiency as we scale Meta AI and other AI services. Some of this will come from improving how we train and run models. Some improvements will come from the open source community, and we're improving cost efficiency is one of the main areas that I expect that open sourcing will help us improve similar to what we saw with Open Compute. We'll also keep making progress on building more of our own silicon. Our Meta training and inference accelerator chip has successfully enabled us to run some of our recommendations-related workloads on this less expensive stack. And as this program matures over the coming years, we plan to expand this to more of our workloads as well. And of course, as we ramp these investments, we will also continue to carefully manage headcount and other expense growth throughout the company.  Now in addition to our work on AI, our other long-term focus is the metaverse. It's been interesting to see how these 2 themes have come together.  This is clearest when you look at glasses. I used to think that AR glasses wouldn't really be a mainstream product until we had full holographic displays -- and I still think that, that's going to be awesome and is the long-term mature state for the product. But now it seems pretty clear that there's also a meaningful market for fashionable AI glasses without a display. Glasses are the ideal device for an AI assistant because you can let them see what you see and hear what you hear. So they have full context on what's going on around you as they help you with whatever you're trying to do. Our launch this week of Meta AI with Vision on the glasses is a good example where you can now ask questions about things that you're looking at.  Now one strategy dynamic that I've been reflecting on is that an increasing amount of our Reality Labs work is going towards serving our AI efforts. We currently report on our financials as if Family of Apps and Reality Labs were 2 completely separate businesses, but strategically, I think of them as fundamentally the same business with the vision of Reality Labs to build the next generation of computing platforms in large part so that we can build the best apps and experiences on top of them. Over time, we'll need to find better ways to articulate the value that's generated here across both segments so it doesn't just seem like our hardware costs increase as our glasses ecosystem scales, but all the value flows to a different segment.  The Ray-Ban Meta glasses that we built with Essilor Luxottica continue to do well and are sold out in many styles and colors. So we're working to make more and release additional styles as quickly as we can. We just released the new cat-eye Skyler design yesterday, which is more feminine. And in general, I'm optimistic about our approach of starting with the classics and expanding with an increasing diversity of options over time. If we want everyone to be able to use wearable AI, I think eyewear is a bit different from phones or watches in that people are going to want very different designs. So I think our approach of partnering with the leading eyewear brands will help us serve more of the market.  I think a similar open ecosystem approach will help us expand the virtual and mixed reality headset market over time as well. We announced that we're opening up Meta Horizon OS, the operating system we've built to power Quest. As the ecosystem grows, I think there will be sufficient diversity in how people use mixed reality, that there will be demand for more designs than we'll be able to build. For example, a work-focused headset may be slightly less designed for motion but may -- you want to be lighter by connecting to your laptop; a fitness-focused headset may be lighter with sweat-wicking materials; an entertainment-focused headset may prioritize the highest resolution displays over everything else; a gaming-focused headset may prioritize peripherals and haptics or a device that comes with Xbox controllers and a game pass subscription out of the box.   Now to be clear, I think that our first-party Quest devices will continue to be the most popular headsets as we see today, and we'll continue focusing on advancing the state-of-the-art tech and making it accessible to everyone. But I also think that opening our ecosystem and opening our operating system will help the overall mixed reality ecosystem grow even faster.   Now in addition to AI and the metaverse, we're seeing good improvements across our apps. I touched on some of the most important trends already with WhatsApp growth in the U.S. and AI-powered recommendations in our feeds and reels already. But I do want to mention that video continues to be a bright spot. This month, we launched an updated full-screen video player on Facebook that brings together reels, longer videos and live content into a single experience with a unified recommendation system. On Instagram, reels and video continue to drive engagement, with reels alone now making up 50% of the time that's spent within the app. Threads is growing well, too. There are now more than 150 million monthly actives, and it continues to generally be on the trajectory that I hoped to see. And of course, my daughters would want me to mention that Taylor Swift is now on Threads, that one was a big deal in my house.  All right. That is what I wanted to cover today. I am proud of the progress we've made so far this year. We've got a lot more execution ahead to fulfill the opportunities ahead of us. A big thank you to all of our teams who are driving all these advances and to all of you for being on this journey with us. And now here is Susan. 

Susan Li: Thanks, Mark, and good afternoon, everyone. Let's begin with our consolidated results. All comparisons are on a year-over-year basis unless otherwise noted. Q1 total revenue was $36.5 billion, up 27% on both a reported and constant currency basis. Q1 total expenses were $22.6 billion, up 6% compared to last year.   In terms of the specific line items, cost of revenue increased 9% as higher infrastructure-related costs were partially offset by lapping Reality Labs' inventory-related valuation adjustments. R&D increased 6%, driven mostly by higher headcount-related expenses and infrastructure costs, which were partially offset by lower restructuring costs.   Marketing and sales decreased 16% due mainly to lower restructuring costs, professional services and marketing spend. G&A increased 20% as higher legal-related expenses were partially offset by lower restructuring costs.   We ended the first quarter with over 69,300 employees, up 3% from Q4. First quarter operating income was $13.8 billion, representing a 38% operating margin. Our tax rate for the quarter was 13%. Net income was $12.4 billion or $4.71 per share.   Capital expenditures, including principal payments on finance leases, were $6.7 billion, driven by investments in servers, data centers and network infrastructure. Free cash flow was $12.5 billion. We repurchased $14.6 billion of our Class A common stock and paid $1.3 billion in dividends to shareholders, ending the quarter with $58.1 billion in cash and marketable securities and $18.4 billion in debt.   Moving now to our segment results. I'll begin with our Family of Apps segment. Our community across the Family of Apps continues to grow, with approximately 3.2 billion people using at least one of our Family of Apps on a daily basis in March. Q1 total Family of Apps revenue was $36 billion, up 27% year-over-year. Q1 Family of Apps ad revenue was $35.6 billion, up 27% or 26% on a constant currency basis. Within ad revenue, the online commerce vertical was the largest contributor to year-over-year growth, followed by gaming and entertainment and media.  On a user geography basis, ad revenue growth was strongest in Rest of World and Europe at 40% and 33%, respectively. Asia Pacific grew 25% and North America grew 22%. In Q1, the total number of ad impressions served across our services increased 20%, and the average price per ad increased 6%. Impression growth was mainly driven by Asia Pacific and Rest of World. Pricing growth was driven by advertiser demand, which was partially offset by strong impression growth, particularly from lower-monetizing regions and services.   Family of Apps other revenue was $380 million in Q1, up 85%, driven by business messaging revenue growth from our WhatsApp business platform. We continue to direct the majority of our investments toward the development and operation of our Family of Apps. In Q1, Family of Apps expenses were $18.4 billion, representing approximately 81% of our overall expenses. Family of Apps expenses were up 7% due mainly to higher legal and infrastructure costs that were partially offset by lower restructuring costs.   Family of Apps operating income was $17.7 billion, representing a 49% operating margin. Within our Reality Labs segment, Q1 revenue was $440 million, up 30%, driven by Quest headset sales. Reality Labs expenses were $4.3 billion, down 1% year-over-year as higher head count-related expenses were more than offset by lapping inventory-related valuation adjustments and restructuring costs. Reality Labs operating loss was $3.8 billion.   Turning now to the business outlook. There are 2 primary factors that drive our revenue performance: our ability to deliver engaging experiences for our community and our effectiveness at monetizing that engagement over time. On the first, we remain pleased with engagement trends and have strong momentum across our product priorities. Our investments in developing increasingly advanced recommendation systems continue to drive incremental engagement on our platform, demonstrating that people are finding added value by discovering content from accounts they are not connected to. The level of recommended content in our apps has scaled as we've improved these systems, and we see further opportunity to increase the relevance and personalization of recommendations as we advance our models.   Video also continues to grow across our platform, and it now represents more than 60% of time on both Facebook and Instagram. Reels remains the primary driver of that growth, and we're progressing on our work to bring together Reel's longer-form video and live video into one experience on Facebook.   In April, we rolled out this unified video experience in the U.S. and Canada, which is increasingly powered by our next-generation ranking architecture that we expect will help deliver more relevant video recommendations over time.   We're also introducing deeper integrations of generative AI into our apps in the U.S. and more than a dozen other countries. Along with using Meta AI within our chat surfaces, people will now be able to use Meta AI in search within our apps as well as feed and groups on Facebook. We expect these integrations will complement our social discovery strategy as our recommendation systems help people to discover and explore their interests, while Meta AI enables them to dive deeper on topics they're interested in. Threads also continues to see good traction as we continue to ship valuable features and scale the community.   Now to the second driver of our revenue performance, increasing monetization efficiency. There are 2 parts to this work. The first is optimizing the level of ads within organic engagement. Here, we continue to advance our understanding of users' preferences for viewing ads to more effectively optimize the right time, place and person to show an ad to.   For example, we are getting better at adjusting the placement and number of ads in real time based on our perception of a user's interest and ad content and to minimize disruption from ads as well as innovating on new and creative ad formats. We expect to continue that work going forward, while surfaces with relatively lower levels of monetization, like video and messaging, will serve as additional growth opportunities.  The second part of improving monetization efficiency is enhancing marketing performance. Similar to our work with organic recommendations, AI is playing an increasing role in these efforts. First, we are making ongoing ads modeling improvements that are delivering better performance for advertisers. One example is our new ads ranking architecture, Meta Lattice, which we began rolling out more broadly last year. This new architecture allows us to run significantly larger models that generalize learnings across objectives and surfaces in place of numerous smaller ad models that have historically been optimized for individual objectives and surfaces. This is not only leading to increased efficiency as we operate fewer models but also improving ad performance.  Another way we're leveraging AI is to provide increased automation for advertisers. Through our Advantage+ portfolio, advertisers can automate one step of the campaign setup process, such as selecting which ad creative to show, or automate their campaign completely using our end-to-end automation tools, Advantage+ shopping and Advantage+ app ads. We're seeing growing use of these solutions, and we expect to drive further adoption over the course of the year while applying what we learned to our broader ads investments.  Next, I'd like to discuss our approach to capital allocation. We continue to see compelling investment opportunities to both improve our core business in the near term and capture significant longer-term opportunities in generative AI and Reality Labs. As we develop more advanced and compute-intensive recommendation models and scale capacity for our generative AI training and inference needs, we expect that having sufficient infrastructure capacity will be critical to realizing many of these opportunities. As a result, we expect that we will invest significantly more in infrastructure over the coming years.  Our other long-term initiatives that we're continuing to make significant investments in is Reality Labs. We are also starting to see our AI initiatives increasingly overlap with our Reality Labs work. For example, with Ray-Ban Meta smart glasses, people in the U.S. and Canada can now use our multimodal Meta AI assistant for daily tasks without pulling out their phone.  Longer term, we expect generative AI to play an increasing role in our mixed reality products, making it easier to develop immersive experiences. Accelerating our AI efforts will help ensure we can provide the best version of our services as we transition to the next computing platform. We expect to pursue these opportunities while maintaining a focus on operating discipline, and we believe our strong financial position will allow us to support these investments while also returning capital to shareholders through share repurchases and dividends.  In addition, we continue to monitor an active regulatory landscape, including the increasing legal and regulatory headwinds in the EU and the U.S. that could significantly impact our business and our financial results. We also have a jury trial scheduled for June in a suit brought by the state of Texas regarding our use of facial recognition technology, which could ultimately result in a material loss.   Turning now to the revenue outlook. We expect second quarter 2024 total revenue to be in the range of $36.5 billion to $39 billion. Our guidance assumes foreign currency is a 1% headwind to year-over-year total revenue growth based on current exchange rates.   Turning now to the expense outlook. We expect full year 2024 total expenses to be in the range of $96 million to $99 billion, updated from our prior outlook of $94 million to $99 billion due to higher infrastructure and legal costs.   For Reality Labs, we continue to expect operating losses to increase meaningfully year-over-year due to our ongoing product development efforts and our investments to further scale our ecosystem.   Turning now to the CapEx outlook. We anticipate our full year 2024 capital expenditures will be in the range of $35 billion to $40 billion, increased from our prior range of $30 billion to $37 billion as we continue to accelerate our infrastructure investments to support our AI road map. While we are not providing guidance for years beyond 2024, we expect CapEx will continue to increase next year as we invest aggressively to support our ambitious AI research and product development efforts.   On to tax. Absent any changes to our tax landscape, we expect our full year 2024 tax rate to be in the mid-teens.   In closing, Q1 was a good start to the year. We're seeing strong momentum within our Family of Apps and are making important progress on our longer-term AI and Reality Labs initiatives that have the potential to transform the way people interact with our services over the coming years.   With that, Krista, let's open up the call for questions. 

Operator: [Operator Instructions] And your first question comes from the line of Eric Sheridan from Goldman Sachs. 

Eric Sheridan: Maybe I'll ask a two-parter. Mark, you used the analogy of other investments cycles you've been through around products like Stories and Reels. I know you're not giving long-term guidance today, but using those analogies, how should investors think about the length and depth of this investment cycle with respect to either AI and/or Reality Labs more broadly and mixed reality?   And you both talked about the impact AI is having on the advertising ecosystem. What are you watching for in terms of adoption or utility on the consumer side to know that AI adoption is tracking along with the investment cycle? 

Mark Zuckerberg: Yes. In terms of the timing, I think it's somewhat difficult to extrapolate from previous cycles. But I guess like the main thing that we see is that we will usually take, I don't know, a couple of years, I mean, it could be a little more, it could be less to focus on building out and scaling the products. And we typically don't focus that much on monetization of the new areas until they reach significant scale because it's so much higher leverage for us just to improve monetization on other things before these new products are at scale.   So you enter this period where I think kind of smart investors see that the product is scaling and that there's a clear monetizable opportunity there even before the revenue materializes. And I think we've seen that with Reels and with Stories and with the shift to mobile and all these things, where basically, we build out the inventory first for a period of time and then we monetize it.   And during that time, when it's scaling, sometimes it's not just the case that we're not making money from that thing. It can often actually be the case that it displaces other revenue from other things. So like you saw with Reels, I mean, it scaled and there was a period where it was not profitable for us as it was scaling before it became profitable. So I think that's more the analogy that I'm making on this.   But I think it's -- what that suggests is that what we should all be focused on for the next period is as the consumer products scale, Meta AI really just launched in a meaningful way so we don't have any kind of hard stats to share on that. But I'd say that's the main thing that I'm focused on for this year and probably a lot of next year is growing that product and the other AI products and the engagement around them. And I think we should all have quite a bit of confidence that if those are on a good track to scale, then they're going to end up being very large businesses. So that's the main point that I was trying to make there. 

Operator: Your next question comes from the line of Brian Nowak from Morgan Stanley. 

Brian Nowak: Thanks for taking my questions, I have 2. The first one is on sort of the recommendation engine improvements and even, Susan, when you talked about further opportunities to increase the relevance of the models. Could you just unpack that a little bit for us? Can you give us examples of where you're still running the model in a suboptimal basis or opportunities for improved signal capture use or data you're not using? Where are sort of the areas of improvement you see from here?   And then the second one, when you talk about driving incremental adoption of AI tools for advertisers, what are sort of some of the main gating factors you've encountered to get advertisers to test these tools? And how do you think about sort of addressing that throughout '24 and '25? 

Susan Li: Thanks, Brian. So to your first question, where are there more opportunities for us to leverage and improve our recommendations models to drive engagement? One of the things I would say is, historically, each of our recommendation products, including Reels, in-feed recommendations, et cetera, has had their own AI model.   And recently, we've been developing a new model architecture with the aim for it to power multiple recommendations products. We started partially validating this model last year by using it to power Facebook Reels. And we saw meaningful performance gains, 8% to 10% increases in watch time as a result of deploying this.   This year, we're actually planning to extend the singular model architecture to recommend content across not just Facebook Reels, but also Facebook's video tab as well. So while it's still too early to share specific results, we're optimistic that the new model architecture will unlock increasingly relevant video recommendations over time. And if it's successful, we'll explore using it to power other recommendations.   And analog exists, I would say, on the ad side. We've talked a little bit about the new model architecture Meta Lattice that we deployed last year that consolidates smaller and more specialized models into larger models that can better learn what characteristics improve ad performance across multiple services, like feed and Reels and multiple types of ads and objectives at the same time. And that's driven improved ad performance over the course of 2023 as we deployed it across Facebook and Instagram to support multiple objectives.   And over the course of 2024, we expect to further enhance model performance and include support for even more objectives like web and app and ROAS. So there's a lot of work that we're investing in, in the underlying model architecture for both organic engagement and ads that we expect is going to continue to deliver increasing ads performance over time.   The second question you asked was around getting advertisers to test and adopt gen AI tools. There are 2 flavors of this. The more near-term version is around the gen AI ad creative features that we have put into our ads creation tools. And it's early, but we're seeing adoption of these features across verticals and different advertiser sizes.   In particular, we've seen outsized adoption of image expansion with small businesses, and this will remain a big area of focus for us in 2024, and I expect that improvements to our underlying foundation models will enhance the quality of the outputs that are generated and support new features on the road map. But right now, we have features supporting text variations, image expansion and background generation, and we're continuing to work to make those more performant for advertisers to create more personalized ads at scale.   The longer-term piece here is around business AIs. We have been testing the ability for businesses to set up AIs for business messaging that represent them in chats with customers, starting by supporting shopping use cases such as responding to people asking for more information on a product or its availability. So this is very, very early. We've been testing this with a handful of businesses on Messenger and WhatsApp, and we're hearing good feedback with businesses saying that the AIs have saved them significant time while customer -- consumers noted more timely response times. And we're also learning a lot from these tests to make these AIs more performant over time as well. So we'll be expanding these tests over the coming months, and we'll continue to take our time here to get it right before we make it more broadly available. 

Operator: Your next question comes from the line of Mark Shmulik from Bernstein Research. 

Mark Shmulik: I guess back to that product playbook that we talked about a few times, with kind of Reels now such a large share of kind of time spent on Instagram and Facebook, how do we think about the next leg of kind of monetization growth from here? In particular, as we kind of get back to kind of shopping on platform or other ways to monetize, any color there on the road map kind of just beyond ad insertion from here?   And then, Susan, just on the ad market, in particular, previously, we heard a lot about kind of Chinese-based advertiser contribution. Any color you could share there on kind of how that spend is trending? 

Susan Li: Sure. Thanks, Mark. So Reels revenue continued to grow across Instagram and Facebook in Q1, and that's driven both by higher engagement and increased monetization efficiency through our ads ranking and delivery improvements. And we -- as we've mentioned before, we don't plan on quantifying the impact from Reels going forward, but it remains a positive contributor to overall revenue. And we expect that there are going to be opportunities for us to continue improving performance and growing supply.    So on the performance improvements, we are investing in ongoing ranking improvements. We're continuing to make ads easier and more intuitive to interact with through work like optimizing call to actions and post-click experiences, which are especially important for DR performance. And we're also optimizing ads to feel more native to Reels.   In Q1, we rolled out our gen AI image expansion tools across Facebook and Instagram Reels after having introduced it to Instagram feed in Q4, and we're seeing, again, outsized adoption with small businesses. So we're excited about the opportunities to continue making these ads more performant. And even though ads -- the Reels ad loads, sorry, has increased over the last year, it remains lower on a per time basis than both Feed and Stories. So we're going to continue to look for opportunities to thoughtfully grow it in the future and invest in creative ways to address the structural supply constraints of the Reels format being more video-heavy, including higher density experiences and formats and increasingly personalizing ad loads, which we think will make sure that we're really putting ads in front of people when they're most likely to be interested and engaged with them.   The second question you asked was around China. Growth in spend from China advertisers remained strong in Q1. This was driven by online commerce and gaming, and it's reflected in our Asia Pacific advertisers segment, which remained the fastest-growing region, at 41% year-over-year in Q1. Now we did see strength across other geographies as well, including a 6-point acceleration in total revenue growth from North America advertisers.   So I would say that we aren't quantifying the Q1 contribution from China, and we don't have forward-looking expectations to share on quarterly China-based ad revenue, but I will say that we are lapping periods of increasingly strong demand over the course of 2024 given the recovery of China-based advertisers in 2023 from their prior pandemic-driven headwinds. 

Operator: Your next question comes from the line of Doug Anmuth from JPMorgan. 

Douglas Anmuth: Can you just talk about what's changed most in your view in the business and the opportunity now versus 3 months ago? And is there anything you're more cautious about in revenue in the ad market? And is the AI opportunity just even bigger, and therefore, requiring more investment than expected?  And then, Susan, can you also just comment on how you're thinking about that ability to sustain growth rates over the next few quarters as you face tougher comps off a big base of ad dollars? 

Mark Zuckerberg: Yes, I can speak to the first one. I think we've gotten more optimistic and ambitious on AI. So previously, I think that our work in this -- I mean when you were looking at last year, when we released Llama 2, we were very excited about the model and thought that, that was going to be the basis to be able to build a number of things that were valuable that integrated into our social products. But now I think we're in a pretty different place. So with the latest models, we're not just building good AI models that are going to be capable of building some new good social and commerce products. I actually think we're in a place where we've shown that we can build leading models and be the leading AI company in the world. And that opens up a lot of additional opportunities beyond just ones that are the most obvious ones for us.   So that's -- this is what I was trying to refer to in my opening remarks where I just view the success that we've seen with the way that Llama 3 and Meta AI have come together as a real validation technically that we have the talent, the data and the ability to scale infrastructure to do leading work here.   And with Meta AI, I think that we are on our path to having Meta AI be the most used and best AI assistant in the world, which I think is going to be enormously valuable. So all of that basically encourages me to make sure that we're investing to stay at the leading edge of this.   And we're doing that at the time when we're also scaling the product before it is making money. So that's the analogy that I was making before, which is we've gone through some of those cycles before. But fundamentally, I think if you look at the facts of what our team is able to produce, I think it just -- our optimism and ambition have just grown quite a bit, and I think that this is just going to end up being quite an important set of products for us. So it was already going to be. Now I think it has the potential to be even more important. 

Susan Li: And I can take that second question, Doug. So we aren't giving full year 2024 guidance. And obviously, our revenue for the full year will be influenced by many factors, including macro conditions and things that are harder to predict the further out you go. And of course, over the course of 2024, we will also be lapping periods of increasingly strong demand. With that said, we expect to see good opportunities to continue growing engagement across our products, driven by the investments we made in AI-based content recommendations, our ongoing video work. And we also expect that we will continue to drive ads performance gains and continue to make our ads sort of more effective and deliver increasing value to advertisers.   One thing I'd share, for example, is that we actually grew conversions at a faster rate than we grew impressions over the course of this quarter. So we are -- we're expecting to -- which basically suggests that our conversion grade is growing and is one of the ways in which our ads are becoming more performant. So I feel like there's a lot of opportunity for us, both with our organic engagement growth and with continuing to make the ads better and to continue driving more results for advertisers. 

Operator: Your next question comes from the line of Justin Post from Bank of America. 

Justin Post: First on the CapEx, mostly, you're kind of talking about an investment cycle here. Is there any way you could kind of use some of the metaverse spend over into AI? Are they converging and kind of use some of the money from the other areas to kind of fund the AI?   And then second, longer-term investors are very focused on returns on capital. Obviously, great returns on CapEx in the past with your margins today. How do we think about the returns on the capital you're spending? How are you thinking about it, I guess, going forward 2, 3 years out? 

Susan Li: So on the -- I would say -- well, I can start with the second part, and then I'll defer to Mark on the first one. In terms of measuring the ROI on our CapEx investments, we've broadly categorized our AI investments into 2 buckets. I think of them as sort of core AI work and then strategic bets, which would include gen AI and the advanced research efforts to support that. And those are just really at different stages as it relates to being able to measure the return and drive revenue for our business. So with our core AI work, we continue to have a very ROI-driven approach to investment, and we're still seeing strong returns as improvements to both engagement and ad performance have translated into revenue gains.   Now the second area, strategic bets, is where we are much earlier. Mark has talked about the potential that we believe we have to create significant value for our business in a number of areas, including opportunities to build businesses that don't exist on us today. But we'll need to invest ahead of that opportunity to develop more advanced models and to grow the usage of our products before they drive meaningful revenue.   So while there is tremendous long-term potential, we're just much earlier on the return curve than with our core AI work. What I'll say though is we're also building our systems in a way that gives us fungibility in how we use our capacity so we can flex it across different use cases as we identify what are the best opportunities to put that infrastructure toward. 

Mark Zuckerberg: And then on the question of shifting resources from other parts of the company. I would say, broadly, we actually are doing that in a lot of places in terms of shifting resources from other areas, whether it's compute resources or different things in order to advance the AI efforts. For Reality Labs specifically, I'm still really optimistic about building these new computing platforms long term. I mentioned in my remarks upfront that one of the bigger areas that we're investing in Reality Labs is glasses. We think that that's going to be a really important platform for the future.   Our outlook for that, I think, has improved quite a bit because previously, we thought that, that would need to wait until we have these full holographic displays to be a large market. And now we're a lot more focused on the glasses that we're delivering in partnership with Ray-Ban, which I think are going really well. And -- so that, I think, has the ability to be a pretty meaningful and growing platform sooner than I would have expected. So it is true that more of the Reality Labs work, like I said, is sort of focused on the AI goals as well. But I still think that we should focus on building these long-term platforms, too. 

Operator: Your next question comes from the line of Youssef Squali from Truist Securities. 

Youssef Squali: Mark, with the upcoming ban or sale of TikTok signed into law earlier today, how do you think that will impact the U.S. social media landscape? And then, in particular, what do you say to people who believe that this is potentially a slippery slope in terms of the government picking up -- picking winners and losers?  And Susan, how big is Advantage+ in terms of the spend on the platform and just in terms of its impact on overall CPM stabilizing? 

Susan Li: Thanks, Youssef. We've obviously been following the events related to TikTok closely, but at this stage, it is just too early, I think, to assess its impact or what it would mean for our business.  To your second question on Advantage+, we're continuing to see good traction across our Advantage+ portfolio, including both with solutions, I mentioned this, that automate individual steps of a campaign creation setup as well as ones that automate the full end-to-end process. So on the single-step automation, Advantage+ audience, for example, has seen significant growth in adoption since we made it the default audience creation experience for most advertisers in Q4. And that enables advertisers to increase campaign performance by just using audience inputs as a suggestion rather than a hard constraint. And based on tests that we ran, campaigns using Advantage+ audience targeting saw, on average, a 28% decrease in cost per click or per objective compared to using our regular targeting.   On the end-to-end automation products like Advantage+ shopping and Advantage+ app campaigns, we're also seeing very strong growth. Mark mentioned the combined revenue flowing through those 2 has more than doubled since last year. And we think there's still significant runway to broaden adoption, so we're trying to enable more conversion types for Advantage+ shopping. In Q1, we began expanding the list of conversions that businesses could optimize for. So previously, it only supported purchase events, and now we've added 10 additional conversion types. And we're continuing to see strong adoption now across verticals.   So generally, I would say we are building a lot more functionality into the Advantage+ tools over time. also where a lot of our gen AI ads creative features have been introduced and where advertisers have the opportunity to experiment with those. And we'll keep looking to apply what we learn from these products more broadly to our ads investments over the course of the year. 

Operator: Your next question comes from the line of Ken Gawrelski from Wells Fargo. 

Kenneth Gawrelski: As you look out through the coming period of product investment, how should we think about the relationship between Family of Apps revenue and cost growth? Is there any insight you can give us there?  And then maybe just one that's a little bit more specific to the G&A growth in 1Q. You called out legal expenses. Just wanted to see if there's anything onetime in there that would cause the elevated growth in 1Q. 

Susan Li: Yes. On the second part of your question first, so on the G&A side, that was really driven by legal expenses. We recognized some accruals in Q1 related to ongoing legal matters, and you'll see more detail on that in the 10-Q.  On the first part of your question, which is really about sort of the kind of long-term margin profile of Family of Apps, we aren't giving guidance on that per se. But one of the things that we really have been very disciplined about over the course of 2023 and continuing is really operating the business in a very efficiency oriented way. So we're being very disciplined with allocation of new resources. This is a muscle that we really built over 2023 that we believe is important for us to keep carrying forward. And I think you'll see us continue to emphasize that, especially with the Family of Apps business being at the scale that it is. 

Operator: Your next question comes from the line of Ross Sandler from Barclays. 

Ross Sandler: Great. Mark, you partnered with Google and Bing for Meta AI organic search citations. So I guess stepping back, do you think that Meta AI longer term could bring in search advertising dollars at some point? Or do you view this as what others are doing, where you kind of attach a premium subscription tier once people kind of get going on it?  And then the second question is, you mentioned that you guys are working on building AI tools for businesses and creators. So just, I guess, how do you see the business model evolving when we all get to the stage of interacting with something like Taylor Swift's custom AI for merchandise or tickets or something like that. How is that going to play out? 

Mark Zuckerberg: All right. So yes, on the Google and Microsoft partnerships, yes, I mean we work with them to have real-time information in Meta AI. It's useful. I think it's pretty different from search. We're not working on search ads or anything like that. I think this will end up being a pretty different business.  I do think that there will be an ability to have ads and paid content in Meta AI interactions over time as well as people being able to pay for whether it's bigger models or more compute or some of the premium features and things like that. But that's all very early in fleshing out.  The thing that I actually think is probably -- the biggest clear opportunity is all the work around business messaging. That's in addition to the stuff that we're already doing, just generate to increase engagement and ads quality in the apps. But business messaging thing, I mean, whether it's a creator or one of the 100-plus million businesses on our platform, we basically want to make it very easy for all of these folks to set up an AI to engage with their community. For a business, that's going to be able to do sales and commerce and customer support. And I think it will be similar for creators, although there will be more of a kind of just fun and engaging part there, but a lot of creators are on the platform because they see this as a business too, whether they're trying to sell concert tickets or products or whatever it is that their business goal is.  And a lot of these folks either aren't advertising as much as they could or, in business, the business messaging parts, I think, are still relatively undermonetized compared to where they will be. And I think a lot of that is because the cost of engaging with people in messaging is still very high. But AI should bring that down just dramatically for businesses and creators. And I think that, that has the potential. That's probably the -- beyond just increasing engagement and increasing the quality of the ads, I think that, that's probably one of the nearer-term opportunities, even though that will -- it's not like next quarter or the quarter after that scaling thing, but it's -- but that's not like a 5-year opportunity either.  So I think -- that is one that I think is going to be pretty exciting to look at. But yes, I mean, as Meta AI scales too, I think that, that will have its own opportunities to monetize, and we'll build that out over time. But like I tried to emphasize, we're in the phase of this where the main goal is getting many hundreds of millions or billions of people to use Meta AI as a core part of what they do. That's the kind of next goal, building something that is super valuable. We think this has the potential to be at a very large scale. And that's sort of the next step on the journey. 

Kenneth Dorell: Krista, we have time for one last question. 

Operator: And that question comes from the line of Ron Josey from Citi. 

Ronald Josey: Mark, I want to follow up on a prior question that you mentioned optimism has grown internally quite a bit just with all the improvements and investments and innovations you're making. And we're seeing that in the experience for a few days of Meta AI. So can you just talk to us maybe how the $400 billion parameter model just might evolve the experience on Meta or how you think things might change over the next, call it, months, years, et cetera, as maybe messaging becomes a greater focus and things along those lines? So just a vision longer term. 

Mark Zuckerberg: Yes. I mean I think that the next phase for a lot of these things are handling more complex tasks and becoming more like agents rather than just chat bots, right? So when I say chatbot, what I mean is you send it a message and it replies to your message, right? So it's almost like almost a 1:1 correspondence.  Whereas what an agent is going to do is you give it an intent or a goal, then it goes off and probably actually performs many queries on its own in the background in order to help accomplish your goal, whether that goal is researching something online or eventually finding the right thing that you're looking to buy. There's a lot of complexity and sort of different things. I think people don't even realize that they will be able to ask computers to do for them.  And I think basically, the larger models and then the more advanced future versions that will be smaller as well are just going to enable much more interesting interactions like that. So I mean if you think about this, I mean, even some of the business use cases that we talked about, you don't really just want like sales or customer support chatbot that can just respond to what you say. And if you're a business, you have a goal, right? You're trying to support your customers well and you're trying to position your products in a certain way and encourage people to buy certain things that map to their interests and would they be interested in? And that's more of like a multiturn interaction, right?  So the type of business agent that you're going to be able to enable with just a chatbot is going to be very naive compared to what we're going to have in a year even, but beyond that, too, is just the reasoning and planning abilities if these things grow to be able to just help guide people through the business process of engaging with whatever your goals are as a creator of a business.  So I think that that's going to be extremely powerful. And I think the opportunity is really big. So -- and on top of that, I think what we've shown now is that we have the ability to build leading models in our company. So I think it makes sense to go for it, and we're going to. And I think it's going to be a really good long-term investment. But I did just want to spell out on this call today, the extent to which we're focusing on this and investing in this for the long term because that's what we do. 

Kenneth Dorell: Great. Thank you for joining us today. We appreciate your time, and we look forward to speaking with you again soon. 

Operator: This concludes today's conference call. Thank you for your participation, and you may now disconnect.